{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "import os\n",
    "\n",
    "_ : bool = load_dotenv(find_dotenv())\n",
    "\n",
    "client : OpenAI = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 15\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchat_completion\u001b[39m(prompt : \u001b[38;5;28mstr\u001b[39m)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m\u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m      4\u001b[0m     response : ChatCompletion \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m      5\u001b[0m         messages\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m      6\u001b[0m             {\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m         stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     )\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m \u001b[43mresponse\u001b[49m:\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m()\n\u001b[0;32m     19\u001b[0m chat_completion(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is 2 + 2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'response' is not defined"
     ]
    }
   ],
   "source": [
    "from openai.types.chat.chat_completion import ChatCompletion\n",
    "\n",
    "def chat_completion(prompt : str)->str:\n",
    "    response : ChatCompletion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\" : \"user\",\n",
    "                \"content\" : prompt\n",
    "            }\n",
    "        ],\n",
    "        model=\"gpt-3.5-turbo-1106\",\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "for part in response:\n",
    "    print(part.choices[0].delta.content or \"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
